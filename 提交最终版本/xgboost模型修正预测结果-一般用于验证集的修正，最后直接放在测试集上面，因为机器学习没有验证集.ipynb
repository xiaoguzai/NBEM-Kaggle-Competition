{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1ebe22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_predict = \n",
      "[0 0 0 0 0]\n",
      "===============\n",
      "predict_res = \n",
      "[0.27627334 0.5        0.5        0.5        0.5       ]\n",
      "==============\n",
      "new_label = \n",
      "[]\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "# -*- coding=utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# train data\n",
    "def get_train_data(data_size=100):\n",
    "    print('get_train_data')\n",
    "    data_label = np.zeros((2*data_size, 1))\n",
    "    # class 1\n",
    "    x1 = np.reshape(np.random.normal(3, 1, data_size), (data_size, 1))\n",
    "    y1 = np.reshape(np.random.normal(4, 1, data_size), (data_size, 1))\n",
    "    print('x1 = ')\n",
    "    print(x1)\n",
    "    print('y1 = ')\n",
    "    print(y1)\n",
    "    data_train = np.concatenate((x1, y1), axis=1)\n",
    "    data_label[0:data_size, :] = 0\n",
    "    print('data_train = ')\n",
    "    print(data_train)\n",
    "    print('data_label = ')\n",
    "    print(data_label)\n",
    "    # class 2\n",
    "    x2 = np.reshape(np.random.normal(1, 1, data_size), (data_size, 1))\n",
    "    y2 = np.reshape(np.random.normal(0.5, 1, data_size), (data_size, 1))\n",
    "    print('x2 = ')\n",
    "    print(x2)\n",
    "    print('y2 = ')\n",
    "    print(y2)\n",
    "    data_train = np.concatenate((data_train, np.concatenate((x2, y2), axis=1)), axis=0)\n",
    "    data_label[data_size:2*data_size, :] = 1\n",
    "    print('data_train = ')\n",
    "    print(data_train)\n",
    "    print('data_label = ')\n",
    "    print(data_label)\n",
    "    return data_train, data_label\n",
    "\n",
    "\n",
    "# test data\n",
    "def get_test_data(start, end, data_size=100):\n",
    "    data1 = (end - start) * np.random.random((data_size, 1)) + start\n",
    "    data2 = (end - start) * np.random.random((data_size, 1)) + start\n",
    "    data_test = np.concatenate((data1, data2), axis=1)\n",
    "    return data_test\n",
    "\n",
    "\n",
    "# show data distribution\n",
    "def plot_data(train_data, data_size, test_data):\n",
    "    plt.figure()\n",
    "    plt.plot(train_data[0:data_size, 0], train_data[0:data_size, 1], 'g.',\n",
    "             train_data[data_size:2*data_size, 0], train_data[data_size:2*data_size, 1], 'b*',\n",
    "             test_data[:, 0], test_data[:, 1], 'rs')\n",
    "    plt.legend(['class1', 'class 2', 'test_data'])\n",
    "    plt.title('Distribution')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('axis1')\n",
    "    plt.ylabel('axis2')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot predict res\n",
    "def plot_predict_data(train_data, data_size, test_data, predict_res1, predict_res2):\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_data[0:data_size, 0], train_data[0:data_size, 1], 'g.',\n",
    "             train_data[data_size:2*data_size, 0], train_data[data_size:2*data_size, 1], 'b*',\n",
    "             test_data[:, 0], test_data[:, 1], 'ms')\n",
    "    plt.legend(['class1', 'class2', 'test_data'])\n",
    "    plt.title('Distribution')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('axis1')\n",
    "    plt.ylabel('axis2')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_data[0:data_size, 0], train_data[0:data_size, 1], 'g.',\n",
    "             train_data[data_size:2 * data_size, 0], train_data[data_size:2 * data_size, 1], 'b*',\n",
    "             predict_res1[:, 0], predict_res1[:, 1], 'ro',\n",
    "             predict_res2[:, 0], predict_res2[:, 1], 'rs')\n",
    "    plt.legend(['class1', 'class2', 'predict1', 'predict2'])\n",
    "    plt.title('Predict res')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('axis1')\n",
    "    plt.ylabel('axis2')\n",
    "    plt.show()\n",
    "\n",
    "# main function\n",
    "import xgboost\n",
    "if __name__ == '__main__':\n",
    "    data_size = 100\n",
    "    r\"\"\"\n",
    "    train_data0, label_data = get_train_data(data_size)  # train data generate\n",
    "    test_data0 = get_test_data(-1, 5, 10)  # test data\n",
    "    print('train_data0 = ')\n",
    "    print(train_data0)\n",
    "    print('==============')\n",
    "    print('label_data = ')\n",
    "    print(label_data)\n",
    "    print('==============')\n",
    "    \"\"\"\n",
    "    train_data0 = np.array([[0.1],[0.2],[0.3],[0.4],[0.5],[0.5],[0.9],[0.4],[0.3],[0.2],[0.1]])\n",
    "    label_data = np.array([0,0,0,0,0,1,0,0,0,0,0])\n",
    "    #plot_data(train_data0, data_size, test_data0)  # plot\n",
    "    # data convert\n",
    "    test_data0 = np.array([[0.1],[0.9],[0.7],[0.5],[0.5]])\n",
    "    train_data = xgb.DMatrix(train_data0, label=label_data)\n",
    "    test_data = xgb.DMatrix(test_data0)\n",
    "    model = xgboost.XGBClassifier(\n",
    "                learning_rate = 0.05,\n",
    "                n_estimators=200,\n",
    "                max_depth=7,\n",
    "                min_child_weight=5,\n",
    "                gamma=0,\n",
    "                subsample=0.7,\n",
    "                reg_alpha=.0005,\n",
    "                colsample_bytree=0.6,\n",
    "                scale_pos_weight=1,\n",
    "                use_label_encoder=False,\n",
    "                eval_metric='logloss',\n",
    "                tree_method='hist'\n",
    "            )\n",
    "    model.fit(train_data0,label_data)\n",
    "    #train_predict = clf.predict(x_train)\n",
    "    test_predict = model.predict(test_data0)\n",
    "    # data training\n",
    "    print(\"test_predict = \")\n",
    "    print(test_predict)\n",
    "    print(\"===============\")\n",
    "    num_round = 10\n",
    "    param = {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 5, 'objective': 'binary:logistic'}\n",
    "    #bst = xgb.train(param, train_data, num_round)\n",
    "\n",
    "    # make prediction\n",
    "    #print('test_data0 = ')\n",
    "    #print(test_data0)\n",
    "    \n",
    "    predict_res = bst.predict(test_data)\n",
    "    print('predict_res = ')\n",
    "    print(predict_res)\n",
    "    print('==============')\n",
    "    index1 = predict_res >= 0.5\n",
    "    res1 = test_data0[index1, :]\n",
    "    res2 = test_data0[~index1, :]\n",
    "    new_label = predict_res[predict_res > 0.5]\n",
    "    print('new_label = ')\n",
    "    print(new_label)\n",
    "    print('============')\n",
    "    # plot prediction result\n",
    "    #plot_predict_data(train_data0, data_size, test_data0, res1, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d56b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
