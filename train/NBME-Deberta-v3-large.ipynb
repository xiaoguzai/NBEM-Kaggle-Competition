{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7082720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "# This must be done before importing transformers\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "transformers_path = Path(\"/home/xiaoguzai/.local/lib/python3.9/site-packages/transformers\")\n",
    "\n",
    "input_dir = Path(\"/home/xiaoguzai/程序/NBME-Score Clinical Patient Notes/代码\")\n",
    "\n",
    "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "if conversion_path.exists():\n",
    "    conversion_path.unlink()\n",
    "\n",
    "#print('convert_file = ')\n",
    "#print(convert_file)\n",
    "#print('conversion_path = ')\n",
    "#print(conversion_path)\n",
    "shutil.copy(convert_file, transformers_path)\n",
    "deberta_v2_path = transformers_path \n",
    "\n",
    "for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n",
    "    filepath = deberta_v2_path/filename\n",
    "    \n",
    "    if filepath.exists():\n",
    "        filepath.unlink()\n",
    "\n",
    "    shutil.copy(input_dir/filename, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89acfd35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n",
    "import transformers\n",
    "tokenizer = DebertaV2TokenizerFast.from_pretrained('/home/xiaoguzai/模型/deberta-v3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ecb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "train = pd.read_csv('/home/xiaoguzai/数据/NBME-Score Clinical Patient Notes/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0c773b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>['dad with recent heart attcak']</td>\n",
       "      <td>['696 724']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>['mom with \"thyroid disease']</td>\n",
       "      <td>['668 693']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>['chest pressure']</td>\n",
       "      <td>['203 217']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>['intermittent episodes', 'episode']</td>\n",
       "      <td>['70 91', '176 183']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>['felt as if he were going to pass out']</td>\n",
       "      <td>['222 258']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                                 annotation              location  \n",
       "0          ['dad with recent heart attcak']           ['696 724']  \n",
       "1             ['mom with \"thyroid disease']           ['668 693']  \n",
       "2                        ['chest pressure']           ['203 217']  \n",
       "3      ['intermittent episodes', 'episode']  ['70 91', '176 183']  \n",
       "4  ['felt as if he were going to pass out']           ['222 258']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74ad032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['annotation'] = train['annotation'].apply(ast.literal_eval)\n",
    "train['location'] = train['location'].apply(ast.literal_eval)\n",
    "features = pd.read_csv('/home/xiaoguzai/数据/NBME-Score Clinical Patient Notes/features.csv')\n",
    "features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7c0451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                               annotation          location  \n",
       "0          [dad with recent heart attcak]         [696 724]  \n",
       "1             [mom with \"thyroid disease]         [668 693]  \n",
       "2                        [chest pressure]         [203 217]  \n",
       "3        [intermittent episodes, episode]  [70 91, 176 183]  \n",
       "4  [felt as if he were going to pass out]         [222 258]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527ba1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>Lightheaded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                               annotation          location  \\\n",
       "0          [dad with recent heart attcak]         [696 724]   \n",
       "1             [mom with \"thyroid disease]         [668 693]   \n",
       "2                        [chest pressure]         [203 217]   \n",
       "3        [intermittent episodes, episode]  [70 91, 176 183]   \n",
       "4  [felt as if he were going to pass out]         [222 258]   \n",
       "\n",
       "                                        feature_text  \n",
       "0  Family-history-of-MI-OR-Family-history-of-myoc...  \n",
       "1                 Family-history-of-thyroid-disorder  \n",
       "2                                     Chest-pressure  \n",
       "3                              Intermittent-symptoms  \n",
       "4                                        Lightheaded  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_notes = pd.read_csv('/home/xiaoguzai/数据/NBME-Score Clinical Patient Notes/patient_notes.csv')\n",
    "train = train.merge(features, on=['feature_num','case_num'],how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849e4e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                               annotation          location  \\\n",
       "0          [dad with recent heart attcak]         [696 724]   \n",
       "1             [mom with \"thyroid disease]         [668 693]   \n",
       "2                        [chest pressure]         [203 217]   \n",
       "3        [intermittent episodes, episode]  [70 91, 176 183]   \n",
       "4  [felt as if he were going to pass out]         [222 258]   \n",
       "\n",
       "                                        feature_text  \\\n",
       "0  Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "1                 Family-history-of-thyroid-disorder   \n",
       "2                                     Chest-pressure   \n",
       "3                              Intermittent-symptoms   \n",
       "4                                        Lightheaded   \n",
       "\n",
       "                                          pn_history  \n",
       "0  HPI: 17yo M presents with palpitations. Patien...  \n",
       "1  HPI: 17yo M presents with palpitations. Patien...  \n",
       "2  HPI: 17yo M presents with palpitations. Patien...  \n",
       "3  HPI: 17yo M presents with palpitations. Patien...  \n",
       "4  HPI: 17yo M presents with palpitations. Patien...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(patient_notes, on=['pn_num','case_num'],how='left')\n",
    "train.head()\n",
    "#这里数据读取有bug，一个history被读取了好多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd5a67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('result_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4a810",
   "metadata": {},
   "source": [
    "## 去除脏数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbe160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ast\n",
    "# incorrect annotation\n",
    "train.loc[338, 'annotation'] = ast.literal_eval('[[\"father heart attack\"]]')\n",
    "train.loc[338, 'location'] = ast.literal_eval('[[\"764 783\"]]')\n",
    "\n",
    "train.loc[621, 'annotation'] = ast.literal_eval('[[\"for the last 2-3 months\"]]')\n",
    "train.loc[621, 'location'] = ast.literal_eval('[[\"77 100\"]]')\n",
    "\n",
    "train.loc[655, 'annotation'] = ast.literal_eval('[[\"no heat intolerance\"], [\"no cold intolerance\"]]')\n",
    "train.loc[655, 'location'] = ast.literal_eval('[[\"285 292;301 312\"], [\"285 287;296 312\"]]')\n",
    "\n",
    "train.loc[1262, 'annotation'] = ast.literal_eval('[[\"mother thyroid problem\"]]')\n",
    "train.loc[1262, 'location'] = ast.literal_eval('[[\"551 557;565 580\"]]')\n",
    "\n",
    "train.loc[1265, 'annotation'] = ast.literal_eval('[[\\'felt like he was going to \"pass out\"\\']]')\n",
    "train.loc[1265, 'location'] = ast.literal_eval('[[\"131 135;181 212\"]]')\n",
    "\n",
    "train.loc[1396, 'annotation'] = ast.literal_eval('[[\"stool , with no blood\"]]')\n",
    "train.loc[1396, 'location'] = ast.literal_eval('[[\"259 280\"]]')\n",
    "\n",
    "train.loc[1591, 'annotation'] = ast.literal_eval('[[\"diarrhoe non blooody\"]]')\n",
    "train.loc[1591, 'location'] = ast.literal_eval('[[\"176 184;201 212\"]]')\n",
    "\n",
    "train.loc[1615, 'annotation'] = ast.literal_eval('[[\"diarrhea for last 2-3 days\"]]')\n",
    "train.loc[1615, 'location'] = ast.literal_eval('[[\"249 257;271 288\"]]')\n",
    "\n",
    "train.loc[1664, 'annotation'] = ast.literal_eval('[[\"no vaginal discharge\"]]')\n",
    "train.loc[1664, 'location'] = ast.literal_eval('[[\"822 824;907 924\"]]')\n",
    "\n",
    "train.loc[1714, 'annotation'] = ast.literal_eval('[[\"started about 8-10 hours ago\"]]')\n",
    "train.loc[1714, 'location'] = ast.literal_eval('[[\"101 129\"]]')\n",
    "\n",
    "train.loc[1929, 'annotation'] = ast.literal_eval('[[\"no blood in the stool\"]]')\n",
    "train.loc[1929, 'location'] = ast.literal_eval('[[\"531 539;549 561\"]]')\n",
    "\n",
    "train.loc[2134, 'annotation'] = ast.literal_eval('[[\"last sexually active 9 months ago\"]]')\n",
    "train.loc[2134, 'location'] = ast.literal_eval('[[\"540 560;581 593\"]]')\n",
    "\n",
    "train.loc[2191, 'annotation'] = ast.literal_eval('[[\"right lower quadrant pain\"]]')\n",
    "train.loc[2191, 'location'] = ast.literal_eval('[[\"32 57\"]]')\n",
    "\n",
    "train.loc[2553, 'annotation'] = ast.literal_eval('[[\"diarrhoea no blood\"]]')\n",
    "train.loc[2553, 'location'] = ast.literal_eval('[[\"308 317;376 384\"]]')\n",
    "\n",
    "train.loc[3124, 'annotation'] = ast.literal_eval('[[\"sweating\"]]')\n",
    "train.loc[3124, 'location'] = ast.literal_eval('[[\"549 557\"]]')\n",
    "\n",
    "train.loc[3858, 'annotation'] = ast.literal_eval('[[\"previously as regular\"], [\"previously eveyr 28-29 days\"], [\"previously lasting 5 days\"], [\"previously regular flow\"]]')\n",
    "train.loc[3858, 'location'] = ast.literal_eval('[[\"102 123\"], [\"102 112;125 141\"], [\"102 112;143 157\"], [\"102 112;159 171\"]]')\n",
    "\n",
    "train.loc[4373, 'annotation'] = ast.literal_eval('[[\"for 2 months\"]]')\n",
    "train.loc[4373, 'location'] = ast.literal_eval('[[\"33 45\"]]')\n",
    "\n",
    "train.loc[4763, 'annotation'] = ast.literal_eval('[[\"35 year old\"]]')\n",
    "train.loc[4763, 'location'] = ast.literal_eval('[[\"5 16\"]]')\n",
    "\n",
    "train.loc[4782, 'annotation'] = ast.literal_eval('[[\"darker brown stools\"]]')\n",
    "train.loc[4782, 'location'] = ast.literal_eval('[[\"175 194\"]]')\n",
    "\n",
    "train.loc[4908, 'annotation'] = ast.literal_eval('[[\"uncle with peptic ulcer\"]]')\n",
    "train.loc[4908, 'location'] = ast.literal_eval('[[\"700 723\"]]')\n",
    "\n",
    "train.loc[6016, 'annotation'] = ast.literal_eval('[[\"difficulty falling asleep\"]]')\n",
    "train.loc[6016, 'location'] = ast.literal_eval('[[\"225 250\"]]')\n",
    "\n",
    "train.loc[6192, 'annotation'] = ast.literal_eval('[[\"helps to take care of aging mother and in-laws\"]]')\n",
    "train.loc[6192, 'location'] = ast.literal_eval('[[\"197 218;236 260\"]]')\n",
    "\n",
    "train.loc[6380, 'annotation'] = ast.literal_eval('[[\"No hair changes\"], [\"No skin changes\"], [\"No GI changes\"], [\"No palpitations\"], [\"No excessive sweating\"]]')\n",
    "train.loc[6380, 'location'] = ast.literal_eval('[[\"480 482;507 519\"], [\"480 482;499 503;512 519\"], [\"480 482;521 531\"], [\"480 482;533 545\"], [\"480 482;564 582\"]]')\n",
    "\n",
    "train.loc[6562, 'annotation'] = ast.literal_eval('[[\"stressed due to taking care of her mother\"], [\"stressed due to taking care of husbands parents\"]]')\n",
    "train.loc[6562, 'location'] = ast.literal_eval('[[\"290 320;327 337\"], [\"290 320;342 358\"]]')\n",
    "\n",
    "train.loc[6862, 'annotation'] = ast.literal_eval('[[\"stressor taking care of many sick family members\"]]')\n",
    "train.loc[6862, 'location'] = ast.literal_eval('[[\"288 296;324 363\"]]')\n",
    "\n",
    "train.loc[7022, 'annotation'] = ast.literal_eval('[[\"heart started racing and felt numbness for the 1st time in her finger tips\"]]')\n",
    "train.loc[7022, 'location'] = ast.literal_eval('[[\"108 182\"]]')\n",
    "\n",
    "train.loc[7422, 'annotation'] = ast.literal_eval('[[\"first started 5 yrs\"]]')\n",
    "train.loc[7422, 'location'] = ast.literal_eval('[[\"102 121\"]]')\n",
    "\n",
    "train.loc[8876, 'annotation'] = ast.literal_eval('[[\"No shortness of breath\"]]')\n",
    "train.loc[8876, 'location'] = ast.literal_eval('[[\"481 483;533 552\"]]')\n",
    "\n",
    "train.loc[9027, 'annotation'] = ast.literal_eval('[[\"recent URI\"], [\"nasal stuffines, rhinorrhea, for 3-4 days\"]]')\n",
    "train.loc[9027, 'location'] = ast.literal_eval('[[\"92 102\"], [\"123 164\"]]')\n",
    "\n",
    "train.loc[9938, 'annotation'] = ast.literal_eval('[[\"irregularity with her cycles\"], [\"heavier bleeding\"], [\"changes her pad every couple hours\"]]')\n",
    "train.loc[9938, 'location'] = ast.literal_eval('[[\"89 117\"], [\"122 138\"], [\"368 402\"]]')\n",
    "\n",
    "train.loc[9973, 'annotation'] = ast.literal_eval('[[\"gaining 10-15 lbs\"]]')\n",
    "train.loc[9973, 'location'] = ast.literal_eval('[[\"344 361\"]]')\n",
    "\n",
    "train.loc[10513, 'annotation'] = ast.literal_eval('[[\"weight gain\"], [\"gain of 10-16lbs\"]]')\n",
    "train.loc[10513, 'location'] = ast.literal_eval('[[\"600 611\"], [\"607 623\"]]')\n",
    "\n",
    "train.loc[11551, 'annotation'] = ast.literal_eval('[[\"seeing her son knows are not real\"]]')\n",
    "train.loc[11551, 'location'] = ast.literal_eval('[[\"386 400;443 461\"]]')\n",
    "\n",
    "train.loc[11677, 'annotation'] = ast.literal_eval('[[\"saw him once in the kitchen after he died\"]]')\n",
    "train.loc[11677, 'location'] = ast.literal_eval('[[\"160 201\"]]')\n",
    "\n",
    "train.loc[12124, 'annotation'] = ast.literal_eval('[[\"tried Ambien but it didnt work\"]]')\n",
    "train.loc[12124, 'location'] = ast.literal_eval('[[\"325 337;349 366\"]]')\n",
    "\n",
    "train.loc[12279, 'annotation'] = ast.literal_eval('[[\"heard what she described as a party later than evening these things did not actually happen\"]]')\n",
    "train.loc[12279, 'location'] = ast.literal_eval('[[\"405 459;488 524\"]]')\n",
    "\n",
    "train.loc[12289, 'annotation'] = ast.literal_eval('[[\"experienced seeing her son at the kitchen table these things did not actually happen\"]]')\n",
    "train.loc[12289, 'location'] = ast.literal_eval('[[\"353 400;488 524\"]]')\n",
    "\n",
    "train.loc[13238, 'annotation'] = ast.literal_eval('[[\"SCRACHY THROAT\"], [\"RUNNY NOSE\"]]')\n",
    "train.loc[13238, 'location'] = ast.literal_eval('[[\"293 307\"], [\"321 331\"]]')\n",
    "\n",
    "train.loc[13297, 'annotation'] = ast.literal_eval('[[\"without improvement when taking tylenol\"], [\"without improvement when taking ibuprofen\"]]')\n",
    "train.loc[13297, 'location'] = ast.literal_eval('[[\"182 221\"], [\"182 213;225 234\"]]')\n",
    "\n",
    "train.loc[13299, 'annotation'] = ast.literal_eval('[[\"yesterday\"], [\"yesterday\"]]')\n",
    "train.loc[13299, 'location'] = ast.literal_eval('[[\"79 88\"], [\"409 418\"]]')\n",
    "\n",
    "train.loc[13845, 'annotation'] = ast.literal_eval('[[\"headache global\"], [\"headache throughout her head\"]]')\n",
    "train.loc[13845, 'location'] = ast.literal_eval('[[\"86 94;230 236\"], [\"86 94;237 256\"]]')\n",
    "\n",
    "train.loc[14083, 'annotation'] = ast.literal_eval('[[\"headache generalized in her head\"]]')\n",
    "train.loc[14083, 'location'] = ast.literal_eval('[[\"56 64;156 179\"]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5d771d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                               annotation          location  \\\n",
       "0          [dad with recent heart attcak]         [696 724]   \n",
       "1             [mom with \"thyroid disease]         [668 693]   \n",
       "2                        [chest pressure]         [203 217]   \n",
       "3        [intermittent episodes, episode]  [70 91, 176 183]   \n",
       "4  [felt as if he were going to pass out]         [222 258]   \n",
       "\n",
       "                                        feature_text  \\\n",
       "0  Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "1                 Family-history-of-thyroid-disorder   \n",
       "2                                     Chest-pressure   \n",
       "3                              Intermittent-symptoms   \n",
       "4                                        Lightheaded   \n",
       "\n",
       "                                          pn_history  \n",
       "0  HPI: 17yo M presents with palpitations. Patien...  \n",
       "1  HPI: 17yo M presents with palpitations. Patien...  \n",
       "2  HPI: 17yo M presents with palpitations. Patien...  \n",
       "3  HPI: 17yo M presents with palpitations. Patien...  \n",
       "4  HPI: 17yo M presents with palpitations. Patien...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0eb9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ea326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "Fold = GroupKFold(n_splits=5)\n",
    "groups = train['pn_num'].values\n",
    "for n, (train_index,val_index) in enumerate(Fold.split(train,train['location'],groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "#按照groups也就是train['pn_num']进行划分\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "train['annotation_length'] = train['annotation'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33efe8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>fold</th>\n",
       "      <th>annotation_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                               annotation          location  \\\n",
       "0          [dad with recent heart attcak]         [696 724]   \n",
       "1             [mom with \"thyroid disease]         [668 693]   \n",
       "2                        [chest pressure]         [203 217]   \n",
       "3        [intermittent episodes, episode]  [70 91, 176 183]   \n",
       "4  [felt as if he were going to pass out]         [222 258]   \n",
       "\n",
       "                                        feature_text  \\\n",
       "0  Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "1                 Family-history-of-thyroid-disorder   \n",
       "2                                     Chest-pressure   \n",
       "3                              Intermittent-symptoms   \n",
       "4                                        Lightheaded   \n",
       "\n",
       "                                          pn_history  fold  annotation_length  \n",
       "0  HPI: 17yo M presents with palpitations. Patien...     4                  1  \n",
       "1  HPI: 17yo M presents with palpitations. Patien...     4                  1  \n",
       "2  HPI: 17yo M presents with palpitations. Patien...     4                  1  \n",
       "3  HPI: 17yo M presents with palpitations. Patien...     4                  2  \n",
       "4  HPI: 17yo M presents with palpitations. Patien...     4                  1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82868272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f32b418",
   "metadata": {},
   "source": [
    "## 统计文本总长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72b4be4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 42146/42146 [00:12<00:00, 3421.54it/s]\n",
      "100%|██████████████████████████████████████| 143/143 [00:00<00:00, 27627.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len = 354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "for text in tqdm(patient_notes['pn_history'].fillna(\"\").values,total=len(patient_notes)):\n",
    "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "    pn_history_lengths.append(length)\n",
    "    \n",
    "features_lengths = []\n",
    "for text in tqdm(features['feature_text'].fillna(\"\").values, total=len(features)):\n",
    "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "    features_lengths.append(length)\n",
    "max_len = max(pn_history_lengths)+max(features_lengths)+3\n",
    "print('max_len = %d'%max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32e08c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,inputs,labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        self.tensors = [torch.tensor(self.inputs),\\\n",
    "                       torch.tensor(self.labels)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return tuple(tensor[index] for tensor in self.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48e47803",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "#下面prepare_input的时候将text和feature_text合在一起很巧妙\n",
    "def prepare_input(text, feature_text):\n",
    "    inputs = tokenizer.encode_plus(text+feature_text,\\\n",
    "                                add_special_tokens=True,\\\n",
    "                                max_length = max_len,\\\n",
    "                                padding = \"max_length\",\\\n",
    "                                return_offsets_mapping = False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v,dtype=torch.long)\n",
    "    return inputs,len(inputs['input_ids'])\n",
    "    #return inputs,inputs['input_ids'].size(0)\n",
    "\n",
    "#打标记的时候还是只放入text的内容，不考虑feature_text的文本内容\n",
    "def create_label(text, annotation_length, location_list):\n",
    "    encoded = tokenizer.encode_plus(text,\\\n",
    "                                add_special_tokens=True,\\\n",
    "                                max_length = max_len,\\\n",
    "                                padding = \"max_length\",\\\n",
    "                                return_offsets_mapping = True)\n",
    "    offset_mapping = encoded['offset_mapping']\n",
    "    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "    label = np.zeros(len(offset_mapping))\n",
    "    label[ignore_idxes] = -1\n",
    "    if annotation_length != 0:\n",
    "        for location in location_list:\n",
    "            #location = 2 4,location = 8 10\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                #loc = ['2','4'],loc = ['8','10']\n",
    "                start_idx = -1\n",
    "                end_idx = -1\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                #start = 2,end = 4;start = 8,end = 10;\n",
    "                #!!!这里的start,end标记的为字符:Character spans indicating \n",
    "                #the location of each annotation within the note.\n",
    "                #注意前面的标注Character spans\n",
    "                for idx in range(len(offset_mapping)):\n",
    "                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                        start_idx = idx - 1\n",
    "                        #print('111start_idx = %d 111'%start_idx)\n",
    "                        #字符比当前字符小的时候，指向前一位\n",
    "                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                        end_idx = idx + 1\n",
    "                        #字符比当前字符大的时候，指向后一位\n",
    "                        #print('222start_idx = %d 222'%end_idx)\n",
    "                if start_idx == -1:\n",
    "                    start_idx = end_idx\n",
    "                    #print('333start_idx = %d 333'%start_idx)\n",
    "                if (start_idx != -1) & (end_idx != -1):\n",
    "                    #print('***start_idx = %d***'%start_idx)\n",
    "                    #print('***end_idx = %d***'%end_idx)\n",
    "                    label[start_idx:end_idx] = 1\n",
    "    return offset_mapping,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21367160",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[train['fold'] != 4]\n",
    "valid_data = train[train['fold'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dae1b350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>fold</th>\n",
       "      <th>annotation_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                               annotation          location  \\\n",
       "0          [dad with recent heart attcak]         [696 724]   \n",
       "1             [mom with \"thyroid disease]         [668 693]   \n",
       "2                        [chest pressure]         [203 217]   \n",
       "3        [intermittent episodes, episode]  [70 91, 176 183]   \n",
       "4  [felt as if he were going to pass out]         [222 258]   \n",
       "\n",
       "                                        feature_text  \\\n",
       "0  Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "1                 Family-history-of-thyroid-disorder   \n",
       "2                                     Chest-pressure   \n",
       "3                              Intermittent-symptoms   \n",
       "4                                        Lightheaded   \n",
       "\n",
       "                                          pn_history  fold  annotation_length  \n",
       "0  HPI: 17yo M presents with palpitations. Patien...     4                  1  \n",
       "1  HPI: 17yo M presents with palpitations. Patien...     4                  1  \n",
       "2  HPI: 17yo M presents with palpitations. Patien...     4                  1  \n",
       "3  HPI: 17yo M presents with palpitations. Patien...     4                  2  \n",
       "4  HPI: 17yo M presents with palpitations. Patien...     4                  1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72e8eae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>fold</th>\n",
       "      <th>annotation_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00041_000</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00041_001</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>[MOM HAS THYROID PROBLEMS]</td>\n",
       "      <td>[532 556]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00041_002</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>[PRESSURE ON HER CHEST]</td>\n",
       "      <td>[263 284]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00041_003</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>[COMES AND GOES, HAPPENED 5-6 TIMES]</td>\n",
       "      <td>[131 145, 150 168]</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00041_004</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  case_num  pn_num  feature_num  \\\n",
       "13  00041_000         0      41            0   \n",
       "14  00041_001         0      41            1   \n",
       "15  00041_002         0      41            2   \n",
       "16  00041_003         0      41            3   \n",
       "17  00041_004         0      41            4   \n",
       "\n",
       "                              annotation            location  \\\n",
       "13                                    []                  []   \n",
       "14            [MOM HAS THYROID PROBLEMS]           [532 556]   \n",
       "15               [PRESSURE ON HER CHEST]           [263 284]   \n",
       "16  [COMES AND GOES, HAPPENED 5-6 TIMES]  [131 145, 150 168]   \n",
       "17                                    []                  []   \n",
       "\n",
       "                                         feature_text  \\\n",
       "13  Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "14                 Family-history-of-thyroid-disorder   \n",
       "15                                     Chest-pressure   \n",
       "16                              Intermittent-symptoms   \n",
       "17                                        Lightheaded   \n",
       "\n",
       "                                           pn_history  fold  annotation_length  \n",
       "13  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...     2                  0  \n",
       "14  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...     2                  1  \n",
       "15  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...     2                  1  \n",
       "16  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...     2                  2  \n",
       "17  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...     2                  0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62a566b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['696 724']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data['location'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bdd05c",
   "metadata": {},
   "source": [
    "## 提取数据进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcc06cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_location_to_offset(text,location_list):\n",
    "    results = np.zeros(len(text))\n",
    "    #以char为级别计算，应该对整个text计算len\n",
    "    for idx, offset_mapping in enumerate(location_list):\n",
    "        try:\n",
    "            start = (int)(offset_mapping[0])\n",
    "            end = (int)(offset_mapping[1])\n",
    "            results[start:end] = 1\n",
    "        except:\n",
    "            continue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26e1a1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 11440/11440 [00:11<00:00, 1002.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train_text,valid_text = [],[]\n",
    "train_input_ids,train_token_type_ids,train_attention_mask = [],[],[]\n",
    "train_offset,train_label = [],[]\n",
    "train_length = []\n",
    "valid_input_ids,valid_token_type_ids,valid_attention_mask = [],[],[]\n",
    "valid_offset,valid_label = [],[]\n",
    "valid_length = []\n",
    "train_origin_label,valid_origin_label = [],[]\n",
    "from tqdm import tqdm\n",
    "for  index,data  in  tqdm(train_data.iterrows(),total=len(train_data)):\n",
    "    #!!!数据这里出现bug，读取的都是一组数据!!!\n",
    "    text = data['pn_history']\n",
    "    feature_text = data['feature_text']\n",
    "    #print('text = ')\n",
    "    #print(text)\n",
    "    inputs,length = prepare_input(text,feature_text)\n",
    "    #train_text.append(text+feature_text)\n",
    "    train_text.append(text)\n",
    "    train_input_ids.append(inputs['input_ids'].tolist())\n",
    "    train_token_type_ids.append(inputs['token_type_ids'].tolist())\n",
    "    train_attention_mask.append(inputs['attention_mask'].tolist())\n",
    "    \n",
    "    annotation_length = data['annotation_length']\n",
    "    \n",
    "    current_offset,current_label = create_label(text,annotation_length=data['annotation_length'],\\\n",
    "                                    location_list=data['location'])\n",
    "    true_label = change_location_to_offset(text,data['location'])\n",
    "    train_origin_label.append(true_label)\n",
    "    train_offset.append(current_offset)\n",
    "    train_label.append(current_label)\n",
    "    train_length.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6df9bc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2860/2860 [00:03<00:00, 920.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for index,data in tqdm(valid_data.iterrows(),total=len(valid_data)):\n",
    "    text = data['pn_history']\n",
    "    feature_text = data['feature_text']\n",
    "    inputs,length = prepare_input(text,feature_text)\n",
    "    #valid_text.append(text+feature_text)\n",
    "    valid_text.append(text)\n",
    "    valid_input_ids.append(inputs['input_ids'].tolist())\n",
    "    valid_token_type_ids.append(inputs['token_type_ids'].tolist())\n",
    "    valid_attention_mask.append(inputs['attention_mask'].tolist())\n",
    "    annotation_length = data['annotation_length']\n",
    "    current_offset,current_label = create_label(text,annotation_length=data['annotation_length'],\\\n",
    "                                 location_list=data['location'])\n",
    "    r\"\"\"\n",
    "    current_label = \n",
    "[-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0........]\n",
    "    data['location'] = ['696 724']\n",
    "    \"\"\"\n",
    "    #true_label = change_location_to_offset(text,data['location'])\n",
    "    #发生bug的地方，true_label的标记错误\n",
    "    valid_offset.append(current_offset)\n",
    "    valid_label.append(data['location'])\n",
    "    valid_length.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d47d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52ed321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self,model):\n",
    "        super(ClassificationModel,self).__init__()\n",
    "        self.model = model\n",
    "        #self.dropout = nn.Dropout(0.2)\n",
    "        #self.fc1 = nn.Linear(768,1)\n",
    "        self.fc1 = nn.Linear(1024,1)\n",
    "        #self.fc1 = nn.Linear(768,1)\n",
    "        \n",
    "    def forward(self,input_ids,token_type_ids,attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids,\\\n",
    "                           token_type_ids=token_type_ids,\\\n",
    "                           attention_mask=attention_mask)\n",
    "        outputs = outputs[0]\n",
    "        #outputs = self.dropout(outputs)\n",
    "        outputs = self.fc1(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25f0c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "def my_collate(batch):\n",
    "    text_list,input_ids_list,offset_list = [],[],[]\n",
    "    token_type_ids_list,attention_mask_list,origin_label_list = [],[],[]\n",
    "    for data in batch:\n",
    "        text_list.append(data[0])\n",
    "        input_ids_list.append(data[1].tolist())\n",
    "        offset_list.append(data[2])\n",
    "        token_type_ids_list.append(data[3].tolist())\n",
    "        attention_mask_list.append(data[4].tolist())\n",
    "        #current_data_list = get_predictions(data[5])\n",
    "        current_data_list = []\n",
    "        for data1 in data[5]:\n",
    "            if ' ' in data1:\n",
    "                for data2 in data1.split(';'):\n",
    "                    data3 = data2.split(' ')\n",
    "                    current_data_list.append([(int)(data3[0]),(int)(data3[1])])\n",
    "        origin_label_list.append(current_data_list)\n",
    "    input_ids_list = torch.tensor(input_ids_list)\n",
    "    token_type_ids_list = torch.tensor(token_type_ids_list)\n",
    "    attention_mask_list = torch.tensor(attention_mask_list)\n",
    "    return text_list,input_ids_list,offset_list,\\\n",
    "           token_type_ids_list,attention_mask_list,origin_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5b9f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,text,input_ids,offset,token_type_ids,attention_mask,label):\n",
    "        self.input_ids = input_ids\n",
    "        self.tensors = [text,\\\n",
    "                        torch.tensor(input_ids,dtype=torch.long),\\\n",
    "                        torch.tensor(offset),\\\n",
    "                       torch.tensor(token_type_ids,dtype=torch.long),\\\n",
    "                       torch.tensor(attention_mask,dtype=torch.long),\\\n",
    "                       torch.tensor(label)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return tuple(tensor[index] for tensor in self.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8937fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset(Dataset):\n",
    "    def __init__(self,text,input_ids,offset,token_type_ids,attention_mask,origin_label):\n",
    "        self.input_ids = input_ids\n",
    "        self.tensors = [text,\\\n",
    "                        torch.tensor(input_ids,dtype=torch.long),\\\n",
    "                        torch.tensor(offset),\\\n",
    "                        torch.tensor(token_type_ids,dtype=torch.long),\\\n",
    "                        torch.tensor(attention_mask,dtype=torch.long),\\\n",
    "                        origin_label]\n",
    "        #这里origin_label放入的为['']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return tuple(tensor[index] for tensor in self.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6e5c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multilabel_loss(model,batch_token_ids,\\\n",
    "                            batch_token_type_ids,\\\n",
    "                            batch_attention_mask,\\\n",
    "                            batch_label):\n",
    "    logit = model(input_ids=batch_token_ids,\\\n",
    "                 attention_mask=batch_attention_mask,\\\n",
    "                 token_type_ids=batch_token_type_ids)\n",
    "    logit = logit.view(-1,1)\n",
    "    batch_label = batch_label.view(-1,1)\n",
    "    loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    loss = loss_fn(logit,batch_label)\n",
    "    torch.set_printoptions(threshold=np.inf)\n",
    "    loss = torch.masked_select(loss,batch_label!=-1)\n",
    "    loss = loss.mean()\n",
    "    #这里的loss不要勿写成logit\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69f6b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_probs(total_text,offsets,predictions):\n",
    "    results = [np.zeros(len(t)) for t in total_text]\n",
    "    #!!!results 长短不一!!!\n",
    "    #以char为级别计算，应该对整个text计算len\n",
    "    torch.set_printoptions(threshold=np.inf)\n",
    "    for i, (offset, prediction) in enumerate(zip(offsets, predictions)):\n",
    "        for idx, (offset_mapping, pred) in enumerate(zip(offset, prediction)):\n",
    "            start = offset_mapping[0]\n",
    "            end = offset_mapping[1]\n",
    "            #results[i][start:end] = ((float)(pred[0].item(),)\n",
    "            results[i][start:end] = pred[0].item()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "068d6911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/xiaoguzai/模型/deberta-v3 were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import DebertaV2Model,DebertaModel\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import itertools\n",
    "deberta = DebertaV2Model.from_pretrained(\"/home/xiaoguzai/模型/deberta-v3-large\")\n",
    "#deberta = DebertaModel.from_pretrained(\"/home/xiaoguzai/模型/deberta\")\n",
    "model = ClassificationModel(deberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5eb2c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2aea1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "384a1288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e28cd535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d595667c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2860/2860 [19:52<00:00,  2.40it/s]\n",
      "100%|█████████████████████████████████████████| 715/715 [01:41<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point = \n",
      "0.8367634697253179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2860/2860 [19:53<00:00,  2.40it/s]\n",
      "100%|█████████████████████████████████████████| 715/715 [01:41<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point = \n",
      "0.8539813571867669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2860/2860 [19:52<00:00,  2.40it/s]\n",
      "100%|█████████████████████████████████████████| 715/715 [01:42<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point = \n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2860/2860 [19:53<00:00,  2.40it/s]\n",
      "100%|█████████████████████████████████████████| 715/715 [01:40<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point = \n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████▋          | 2101/2860 [15:15<05:30,  2.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14275/166722129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mbatch_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         loss = compute_multilabel_loss(model,batch_ids,\\\n\u001b[0m\u001b[1;32m     39\u001b[0m                             \u001b[0mbatch_token_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                             \u001b[0mbatch_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14275/1441950344.py\u001b[0m in \u001b[0;36mcompute_multilabel_loss\u001b[0;34m(model, batch_token_ids, batch_token_type_ids, batch_attention_mask, batch_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0mbatch_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             batch_label):\n\u001b[0;32m----> 5\u001b[0;31m     logit = model(input_ids=batch_token_ids,\\\n\u001b[0m\u001b[1;32m      6\u001b[0m                  \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                  token_type_ids=batch_token_type_ids)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14275/1297955120.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         outputs = self.model(input_ids=input_ids,\\\n\u001b[0m\u001b[1;32m     12\u001b[0m                            \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                            attention_mask=attention_mask)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1059\u001b[0m         )\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 )\n\u001b[1;32m    492\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 output_states = layer_module(\n\u001b[0m\u001b[1;32m    494\u001b[0m                     \u001b[0mnext_kv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     ):\n\u001b[0;32m--> 337\u001b[0;31m         attention_output = self.attention(\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     ):\n\u001b[0;32m--> 268\u001b[0;31m         self_output = self.self(\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m             rel_att = self.disentangled_attention_bias(\n\u001b[0m\u001b[1;32m    696\u001b[0m                 \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mdisentangled_attention_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0matt_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ebd_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mrelative_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ebd_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0matt_span\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ebd_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0matt_span\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset = TrainDataset(train_text,\\\n",
    "                             train_input_ids,\\\n",
    "                             train_offset,\\\n",
    "                            train_token_type_ids,\\\n",
    "                            train_attention_mask,\\\n",
    "                            train_label)\n",
    "valid_dataset = ValidDataset(valid_text,\\\n",
    "                             valid_input_ids,\\\n",
    "                             valid_offset,\\\n",
    "                            valid_token_type_ids,\\\n",
    "                            valid_attention_mask,\\\n",
    "                            valid_label)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=4,shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset,batch_size=4,shuffle=False,collate_fn = my_collate)\n",
    "#bcewithlogitloss有sigmoid函数,batch_size必须要大\n",
    "bestpoint = 0.0\n",
    "for epoch in range(5):\n",
    "    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    #model = torch.load(\"/home/xiaoguzai/程序/NBME-Score Clinical Patient Notes/best_point=0.8127543174426041.pth\")\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=1e-5)\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch > 5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2/(epoch+1)\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "    \n",
    "    for batch_text,batch_ids,batch_offset,batch_token_type_ids,batch_attention_mask,batch_label in tqdm(train_loader):\n",
    "        batch_ids = batch_ids.to(device)\n",
    "        batch_token_type_ids = batch_token_type_ids.to(device)\n",
    "        batch_attention_mask = batch_attention_mask.to(device)\n",
    "        batch_label = batch_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = compute_multilabel_loss(model,batch_ids,\\\n",
    "                            batch_token_type_ids,\\\n",
    "                            batch_attention_mask,\\\n",
    "                            batch_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    pred_result = []\n",
    "    label_result = []\n",
    "    for batch_text,batch_ids,batch_offset,batch_token_type_ids,batch_attention_mask,batch_origin_label in tqdm(valid_loader):\n",
    "        #print('batch_origin_label = ')\n",
    "        #print(batch_origin_label)\n",
    "        #print('=====================')\n",
    "        batch_ids = batch_ids.to(device)\n",
    "        batch_token_type_ids = batch_token_type_ids.to(device)\n",
    "        batch_attention_mask = batch_attention_mask.to(device)\n",
    "        with torch.no_grad():\n",
    "            logit = model(input_ids=batch_ids,token_type_ids=batch_token_type_ids,\\\n",
    "                          attention_mask=batch_attention_mask)\n",
    "            #logit = model(input_ids=batch_ids)\n",
    "            #logit = (4,512,1)\n",
    "            #!!!这点判断需要注意应该是以字符的形式进行判断!!!\n",
    "            #输入的id应该为text+symptom，但是判断正负的时候只应该判断text的内容\n",
    "            #torch.set_printoptions(threshold=np.inf)\n",
    "            logit = torch.sigmoid(logit)\n",
    "            #加上symptom得到的正常的logit\n",
    "            preds = get_char_probs(batch_text,batch_offset,\\\n",
    "                                   logit.cpu())\n",
    "            r\"\"\"\n",
    "            preds = \n",
    "            [[4.64789191e-05 5.17649823e-05 5.17649823e-05 ... 7.39335519e-05\n",
    "              7.39335519e-05 7.39335519e-05]\n",
    "             [5.17546650e-05 5.56675914e-05 5.56675914e-05 ... 5.40796318e-05\n",
    "              5.40796318e-05 5.40796318e-05]\n",
    "             [3.96486830e-05 4.77852955e-05 4.77852955e-05 ... 1.11369292e-04\n",
    "              1.11369292e-04 1.11369292e-04]\n",
    "             [4.52924432e-05 5.60515546e-05 5.60515546e-05 ... 5.00233182e-05\n",
    "              5.00233182e-05 5.00233182e-05]]\n",
    "            \"\"\"\n",
    "            results = get_results(preds,th=0.5)\n",
    "            preds = get_predictions(results)\n",
    "            truths = batch_origin_label\n",
    "            r\"\"\"\n",
    "            preds = \n",
    "            [[[696, 722]], [[668, 693]], [[203, 217]], [[70, 91]]]\n",
    "            truths = \n",
    "            [[[696, 724]], [[668, 693]], [[203, 217]], [[70, 91], [176, 183]]]\n",
    "            \"\"\"\n",
    "            for data in preds:\n",
    "                pred_result.append(data)\n",
    "            for data in truths:\n",
    "                label_result.append(data)\n",
    "\n",
    "    point = get_score(pred_result,label_result)\n",
    "    print('point = ')\n",
    "    print(point)\n",
    "    if point > bestpoint:\n",
    "        bestpoint = point \n",
    "        torch.save(model,'best_point='+str(bestpoint)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a21e763b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965]],\n",
       "\n",
       "        [[0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965]],\n",
       "\n",
       "        [[0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965]],\n",
       "\n",
       "        [[0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.0116],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965],\n",
       "         [0.5965]]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "848495b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], []]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9d77734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [[274, 282]], [[421, 437]], [[314, 330]]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7fa053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
